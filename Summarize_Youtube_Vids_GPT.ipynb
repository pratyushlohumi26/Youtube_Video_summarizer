{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratyushlohumi26/Youtube_Video_summarizer/blob/main/Summarize_Youtube_Vids_GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2addFhkCiTEH"
      },
      "source": [
        "\n",
        "# Summarize any YouTube video using whisper and chatGPT\n",
        "\n",
        "## How it works ü§î\n",
        "\n",
        "![yougptube](https://user-images.githubusercontent.com/18450628/229377710-95fb8645-3d71-47d0-b3ba-0fd05941b083.png)\n",
        "\n",
        "Here are the main steps:\n",
        "\n",
        "1) Extract the audio using youtube-dl, yt-dl\n",
        "\n",
        "2) Process the audio into smaller chunks\n",
        "\n",
        "3) Each chunk is transcribed using whisper, OpenAI's powerful speech2text model\n",
        "\n",
        "4) Each transcription is summarized using ChatGPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx_hR_-8iTES"
      },
      "source": [
        "## Imports and dependenciesÔ∏è ‚öôÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88vH9KPgievK",
        "outputId": "2afd81f1-834b-4ff2-ac1a-6ce29c97433b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for youtube-dl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for yt-dlp (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q openai youtube_dl gradio youtube_transcript_api torch sentencepiece transformers\n",
        "!pip install -q --upgrade --force-reinstall \"git+https://github.com/ytdl-org/youtube-dl.git\"\n",
        "!python3 -m pip install -q --force-reinstall https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QOyRBqB9iTET"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import librosa\n",
        "import openai\n",
        "import soundfile as sf\n",
        "from youtube_dl.utils import DownloadError\n",
        "import yt_dlp as youtube_dl\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"API_KEY\"\n",
        "openai.api_key = \"API_KEY\"\n",
        "assert os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjJI0I5ziTEX"
      },
      "source": [
        "## Utility functions üîã"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eCbOXe8PiTEZ"
      },
      "outputs": [],
      "source": [
        "def find_audio_files(path, extension=\".mp3\"):\n",
        "    \"\"\"Recursively find all files with extension in path.\"\"\"\n",
        "    audio_files = []\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for f in files:\n",
        "            if f.endswith(extension):\n",
        "                audio_files.append(os.path.join(root, f))\n",
        "\n",
        "    return audio_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P09Yx-3ziTEa"
      },
      "source": [
        "## Download youtube audio üîà"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kUItfxRniTEb"
      },
      "outputs": [],
      "source": [
        "def youtube_to_mp3(youtube_url: str, output_dir: str) -> str:\n",
        "    \"\"\"Download the audio from a youtube video, save it to output_dir as an .mp3 file.\n",
        "\n",
        "    Returns the filename of the savied video.\n",
        "    \"\"\"\n",
        "\n",
        "    # config\n",
        "    ydl_config = {\n",
        "        \"format\": \"bestaudio/best\",\n",
        "        \"postprocessors\": [\n",
        "            {\n",
        "                \"key\": \"FFmpegExtractAudio\",\n",
        "                \"preferredcodec\": \"mp3\",\n",
        "                \"preferredquality\": \"192\",\n",
        "            }\n",
        "        ],\n",
        "        \"outtmpl\": os.path.join(output_dir, \"%(title)s.%(ext)s\"),\n",
        "        \"verbose\": True,\n",
        "    }\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    print(f\"Downloading video from {youtube_url}\")\n",
        "\n",
        "    try:\n",
        "        with youtube_dl.YoutubeDL(ydl_config) as ydl:\n",
        "            ydl.download([youtube_url])\n",
        "    except DownloadError:\n",
        "        # weird bug where youtube-dl fails on the first download, but then works on second try... hacky ugly way around it.\n",
        "        with youtube_dl.YoutubeDL(ydl_config) as ydl:\n",
        "            ydl.download([youtube_url])\n",
        "\n",
        "    audio_filename = find_audio_files(output_dir)[0]\n",
        "    return audio_filename"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYEdx4_TiTEd"
      },
      "source": [
        "## Chunk the audio üç™\n",
        "\n",
        "Chunking is necessary in the case where we have very long audio files, since both whisper and ChatGPT have limits of how much audio/text you can process in one go.\n",
        "It is not necessary for shorter videos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b7vQl0o8iTEf"
      },
      "outputs": [],
      "source": [
        "def chunk_audio(filename, segment_length: int, output_dir):\n",
        "    \"\"\"segment lenght is in seconds\"\"\"\n",
        "\n",
        "    print(f\"Chunking audio to {segment_length} second segments...\")\n",
        "\n",
        "    if not os.path.isdir(output_dir):\n",
        "        os.mkdir(output_dir)\n",
        "\n",
        "    # load audio file\n",
        "    audio, sr = librosa.load(filename, sr=44100)\n",
        "\n",
        "    # calculate duration in seconds\n",
        "    duration = librosa.get_duration(y=audio, sr=sr)\n",
        "\n",
        "    # calculate number of segments\n",
        "    num_segments = int(duration / segment_length) + 1\n",
        "\n",
        "    print(f\"Chunking {num_segments} chunks...\")\n",
        "\n",
        "    # iterate through segments and save them\n",
        "    for i in range(num_segments):\n",
        "        start = i * segment_length * sr\n",
        "        end = (i + 1) * segment_length * sr\n",
        "        segment = audio[start:end]\n",
        "        sf.write(os.path.join(output_dir, f\"segment_{i}.mp3\"), segment, sr)\n",
        "\n",
        "    chunked_audio_files = find_audio_files(output_dir)\n",
        "    return sorted(chunked_audio_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsTiHE1DiTEg"
      },
      "source": [
        "## Speech2text üó£\n",
        "\n",
        "Here we use OpenAI's whisper model to transcribe audio files to text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "khcR56ggiTEg"
      },
      "outputs": [],
      "source": [
        "\n",
        "def transcribe_audio(youtube_url, audio_files: list = '', output_file=None, model=\"whisper-1\") -> list:\n",
        "\n",
        "    print(\"converting audio to text...\")\n",
        "\n",
        "    video_id = youtube_url.split(\"=\")[1]\n",
        "\n",
        "    # try:\n",
        "    #   transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "    #   FinalTranscript = ' '.join([i['text'] for i in transcript])\n",
        "    #   print(\"Total length of the transcript: \", len(FinalTranscript))\n",
        "\n",
        "    # except Exception as e:\n",
        "    #     print(\"TranscriptsDisabled: Transcript is not available \\nTry another video\")\n",
        "    transcripts = []\n",
        "    for audio_file in audio_files:\n",
        "        audio = open(audio_file, \"rb\")\n",
        "        response = openai.Audio.transcribe(\"whisper-1\", audio)\n",
        "        transcripts.append(response[\"text\"])\n",
        "\n",
        "    if output_file is not None:\n",
        "        # save all transcripts to a .txt file\n",
        "        with open(output_file, \"w\") as file:\n",
        "            for transcript in transcripts:\n",
        "                file.write(transcript + \"\\n\")\n",
        "    # start = 0\n",
        "    # end = 3000\n",
        "    # chunk_size = 3000\n",
        "    # for i in range(0, len(FinalTranscript), chunk_size):\n",
        "    #     chunk = FinalTranscript[i:i+chunk_size]\n",
        "    #     transcripts.append(chunk)\n",
        "    return transcripts"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For Faster Inference, use the Youtube Transcript API"
      ],
      "metadata": {
        "id": "xukHPaR7nHgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Takes the whole YT transcript and divide it into a chunk size of 3000 characters and shares a list of transcript\n",
        "\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "def get_youtube_transcript(youtube_url, audio_files: list = '', output_file=None, model=\"whisper-1\") -> list:\n",
        "    print(\"converting audio to text...\")\n",
        "\n",
        "    video_id = youtube_url.split(\"=\")[1]\n",
        "\n",
        "    try:\n",
        "      transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "      FinalTranscript = ' '.join([i['text'] for i in transcript])\n",
        "      print(\"Total length of the transcript: \", len(FinalTranscript))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"TranscriptsDisabled: Transcript is not available \\nTry another video\")\n",
        "    transcripts = []\n",
        "    chunk_size = 3000\n",
        "    for i in range(0, len(FinalTranscript), chunk_size):\n",
        "        chunk = FinalTranscript[i:i+chunk_size]\n",
        "        transcripts.append(chunk)\n",
        "    return transcripts\n"
      ],
      "metadata": {
        "id": "hNRmopDPnGtE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxC__YjJiTEh"
      },
      "source": [
        "## Summarize üìù\n",
        "\n",
        "Here we ask chatGPT to take the raw transcripts and transcribe them for us to short bullet points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1kGs7cM3iTEh"
      },
      "outputs": [],
      "source": [
        "def summarize(\n",
        "    chunks: list[str], system_prompt: str, model=\"gpt-3.5-turbo\", output_file=None\n",
        "):\n",
        "\n",
        "    print(f\"Summarizing with {model=}\")\n",
        "\n",
        "    summaries = []\n",
        "    for chunk in chunks:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": chunk},\n",
        "            ],\n",
        "        )\n",
        "        summary = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "        summaries.append(summary)\n",
        "\n",
        "    if output_file is not None:\n",
        "        # save all transcripts to a .txt file\n",
        "        with open(output_file, \"w\") as file:\n",
        "            for summary in summaries:\n",
        "                file.write(summary + \"\\n\")\n",
        "\n",
        "    return summaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRtf83SdiTEi"
      },
      "source": [
        "## Putting it all together üç±"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_youtube_video_with_youtube_transcript(youtube_url, outputs_dir=\"outputs/\"):\n",
        "    raw_audio_dir = f\"{outputs_dir}/raw_audio/\"\n",
        "    chunks_dir = f\"{outputs_dir}/chunks\"\n",
        "    transcripts_file = f\"{outputs_dir}/transcripts.txt\"\n",
        "    summary_file = f\"{outputs_dir}/summary.txt\"\n",
        "\n",
        "    if os.path.exists(outputs_dir):\n",
        "        # delete the outputs_dir folder and start from scratch\n",
        "        shutil.rmtree(outputs_dir)\n",
        "        os.mkdir(outputs_dir)\n",
        "\n",
        "    # transcribe whole video using transcript api and get the chunked transcripts\n",
        "    transcriptions = get_youtube_transcript(youtube_url, transcripts_file)\n",
        "\n",
        "    # summarize each transcription using chatGPT\n",
        "    system_prompt = \"\"\"\n",
        "    You are a helpful assistant that summarizes youtube videos.\n",
        "    You are provided chunks of raw audio that were transcribed from the video's audio.\n",
        "    Summarize the current chunk to succint and clear bullet points of its contents.\n",
        "    \"\"\"\n",
        "    summaries = summarize(\n",
        "        transcriptions, system_prompt=system_prompt, output_file=summary_file\n",
        "    )\n",
        "\n",
        "    system_prompt_tldr = \"\"\"\n",
        "    You are a helpful assistant that summarizes youtube videos.\n",
        "    Someone has already summarized the video to key points.\n",
        "    Summarize the key points to a short summary capture the essence of the video.\n",
        "    \"\"\"\n",
        "    # put the entire summary to a single entry\n",
        "    long_summary = \"\\n\".join(summaries)\n",
        "    short_summary = summarize(\n",
        "        [long_summary], system_prompt=system_prompt_tldr, output_file=summary_file\n",
        "    )[0]\n",
        "\n",
        "    return short_summary#, long_summary"
      ],
      "metadata": {
        "id": "Ep-Mgp-IoGDP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HNh32H54iTEi"
      },
      "outputs": [],
      "source": [
        "def summarize_youtube_video_with_whisper(youtube_url, outputs_dir=\"outputs/\"):\n",
        "    raw_audio_dir = f\"{outputs_dir}/raw_audio/\"\n",
        "    chunks_dir = f\"{outputs_dir}/chunks\"\n",
        "    transcripts_file = f\"{outputs_dir}/transcripts.txt\"\n",
        "    summary_file = f\"{outputs_dir}/summary.txt\"\n",
        "    segment_length = 15 * 60  # chunk to 15 minute segments\n",
        "\n",
        "    if os.path.exists(outputs_dir):\n",
        "        # delete the outputs_dir folder and start from scratch\n",
        "        shutil.rmtree(outputs_dir)\n",
        "        os.mkdir(outputs_dir)\n",
        "\n",
        "    # download the video using youtube-dl\n",
        "    audio_filename = youtube_to_mp3(youtube_url, output_dir=raw_audio_dir)\n",
        "\n",
        "    # chunk each audio file to shorter audio files (not necessary for shorter videos...)\n",
        "    chunked_audio_files = chunk_audio(\n",
        "        audio_filename, segment_length=segment_length, output_dir=chunks_dir\n",
        "    )\n",
        "\n",
        "    # transcribe each chunked audio file using whisper speech2text\n",
        "    transcriptions = transcribe_audio(youtube_url, transcripts_file)\n",
        "\n",
        "    # summarize each transcription using chatGPT\n",
        "    system_prompt = \"\"\"\n",
        "    You are a helpful assistant that summarizes youtube videos.\n",
        "    You are provided chunks of raw audio that were transcribed from the video's audio.\n",
        "    Summarize the current chunk to succint and clear bullet points of its contents.\n",
        "    \"\"\"\n",
        "    summaries = summarize(\n",
        "        transcriptions, system_prompt=system_prompt, output_file=summary_file\n",
        "    )\n",
        "\n",
        "    system_prompt_tldr = \"\"\"\n",
        "    You are a helpful assistant that summarizes youtube videos.\n",
        "    Someone has already summarized the video to key points.\n",
        "    Summarize the key points to a short summary capture the essence of the video.\n",
        "    \"\"\"\n",
        "    # put the entire summary to a single entry\n",
        "    long_summary = \"\\n\".join(summaries)\n",
        "    short_summary = summarize(\n",
        "        [long_summary], system_prompt=system_prompt_tldr, output_file=summary_file\n",
        "    )[0]\n",
        "\n",
        "    return short_summary#, long_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bloVZQMliTEj"
      },
      "outputs": [],
      "source": [
        "# import time\n",
        "\n",
        "# t0 = time.time()\n",
        "# youtube_url = \"https://www.youtube.com/watch?v=zie_xSa2oRc&ab_channel=DanLok\"\n",
        "# outputs_dir = \"outputs/\"\n",
        "\n",
        "# short_summary = summarize_youtube_video_with_whisper(youtube_url, outputs_dir)\n",
        "# t1 = time.time()\n",
        "# print(\"Summaries:\")\n",
        "# print(\"=\" * 80)\n",
        "# # print(\"Long summary:\")\n",
        "# # print(\"=\" * 80)\n",
        "# # print(long_summary)\n",
        "# # print()\n",
        "\n",
        "# print(\"=\" * 80)\n",
        "# print(\"Video - TL;DR\")\n",
        "# print(\"=\" * 80)\n",
        "# print(short_summary)\n",
        "\n",
        "\n",
        "# total = t1-t0\n",
        "# print(\"Time taken to process this video : \", total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpHSgHu0iTEl",
        "outputId": "766d4041-e7ef-4d3d-e44e-7a637764cc41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "converting audio to text...\n",
            "Total length of the transcript:  10142\n",
            "Summarizing with model='gpt-3.5-turbo'\n",
            "Summarizing with model='gpt-3.5-turbo'\n",
            "Summaries:\n",
            "================================================================================\n",
            "================================================================================\n",
            "Video - TL;DR\n",
            "================================================================================\n",
            "In this video, the speaker discusses a strategy to sell anything to anyone by focusing on creating trust and certainty in the mind of the prospect. The importance of standing out in a crowded marketplace and using showmanship to capture attention is emphasized. The power of dramatic demonstration is highlighted through examples such as a vacuum cleaner infomercial and Tony Robbins' use of dramatic demonstrations to launch his programs. The speaker also shares personal examples of using dramatic demonstrations in their career. The benefits of creating a \"WTF effect\" and combining it with massive distribution are discussed. The video concludes with an invitation to join a free web class on the advanced psychology of closing and selling.\n",
            "Time taken to process this video :  25.884984016418457\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "youtube_url = \"https://www.youtube.com/watch?v=zie_xSa2oRc&ab_channel=DanLok\"#\"https://www.youtube.com/watch?v=89Vpqm2IaPE&ab_channel=RobMoore\"\n",
        "\n",
        "outputs_dir = \"outputs/\"\n",
        "\n",
        "short_summary = summarize_youtube_video_with_youtube_transcript(youtube_url, outputs_dir)\n",
        "t1 = time.time()\n",
        "print(\"Summaries:\")\n",
        "print(\"=\" * 80)\n",
        "# print(\"Long summary:\")\n",
        "# print(\"=\" * 80)\n",
        "# print(long_summary)\n",
        "# print()\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"Video - TL;DR\")\n",
        "print(\"=\" * 80)\n",
        "print(short_summary)\n",
        "\n",
        "\n",
        "\n",
        "total = t1-t0\n",
        "print(\"Time taken to process this video : \", total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "jsJ5ba4xsiXE",
        "outputId": "7262f3e3-3a17-4db2-fab4-7bb9639e121a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-2c16865e9f95>:5: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  inputs = [gr.inputs.Textbox(lines=2,\n",
            "<ipython-input-29-2c16865e9f95>:5: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  inputs = [gr.inputs.Textbox(lines=2,\n",
            "<ipython-input-29-2c16865e9f95>:5: GradioDeprecationWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  inputs = [gr.inputs.Textbox(lines=2,\n",
            "<ipython-input-29-2c16865e9f95>:9: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  outputs = [gr.outputs.Textbox(\n",
            "<ipython-input-29-2c16865e9f95>:4: GradioDeprecationWarning: `enable_queue` is deprecated in `Interface()`, please use it within `launch()` instead.\n",
            "  interface = gr.Interface(fn = summarize_youtube_video_with_youtube_transcript,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://0e07028f1871d9af3b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0e07028f1871d9af3b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "converting audio to text...\n",
            "Total length of the transcript:  10142\n",
            "Summarizing with model='gpt-3.5-turbo'\n",
            "Summarizing with model='gpt-3.5-turbo'\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://0e07028f1871d9af3b.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "interface = gr.Interface(fn = summarize_youtube_video_with_youtube_transcript,\n",
        "                        inputs = [gr.inputs.Textbox(lines=2,\n",
        "                                                    placeholder=\"Enter your link...\",\n",
        "                                                    label='YouTube Video Link')\n",
        "                                  ],\n",
        "                        outputs = [gr.outputs.Textbox(\n",
        "                                                      label=\"Summary\")],\n",
        "\n",
        "                        title = \"Youtube Summarizer\",\n",
        "                        examples = [['https://www.youtube.com/watch?v=A4OmtyaBHFE'],\n",
        "                                   ['https://www.youtube.com/watch?v=cU6xVZfkcgo']],\n",
        "                        enable_queue=True)\n",
        "\n",
        "interface.launch(debug=True, share=True)\n",
        "# iface = gr.Interface(\n",
        "#     fn=summarize_youtube_video_with_youtube_transcript,\n",
        "#     inputs=\"text\",\n",
        "#     outputs=[\"text\"],  # Render two text outputs\n",
        "#     title=\"YT Summarizer\",\n",
        "#     description=\"Enter a URL, and this app will provide both short and long summaries of its content.\",\n",
        "#     theme=\"default\"\n",
        "# )\n",
        "\n",
        "# iface.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "youGPTube",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}